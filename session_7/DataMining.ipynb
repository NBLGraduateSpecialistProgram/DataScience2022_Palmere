{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sitting-above",
   "metadata": {},
   "source": [
    "### Data Mining the PDB\n",
    "Robert Palmere, 2021\\\n",
    "email: rdp135@chem.rutgers.edu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdb import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-anatomy",
   "metadata": {},
   "source": [
    "Perhaps we are interested in which residues are most likely to be solvent exposed across the span of proteins related to membranes.\n",
    "\n",
    "Our code will need to:\n",
    "\n",
    "1. Acquire data from the PDB\n",
    "2. Render Python handles to textual data of the PDB\n",
    "3. Make calculations based on a user-defined function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-possible",
   "metadata": {},
   "source": [
    "Let's write a function to handle the parsing of PDB file text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floatcustom(s: str):\n",
    "    '''Function to cast string to float with exception for unseparated coordinate values\n",
    "    i.e. '-153.534-108.134' returns [-153.534, -108.134]\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    s : str\n",
    "        string that should have been parsed properly but PDB didn't account for '-'\n",
    "    '''\n",
    "    try:\n",
    "         return float(s)\n",
    "    except:\n",
    "        indices = []\n",
    "        floats_ = []\n",
    "        for index, char in enumerate(s): \n",
    "            if char == '-':\n",
    "                indices.append(index)\n",
    "        if len(indices) > 1 and ' ' not in s:\n",
    "            for n, i in enumerate(indices):\n",
    "                if n >= 1:\n",
    "                    floats_.append(float(s[indices[n-1]:indices[n]]))\n",
    "            floats_.append(float(s[indices[-1]:]))\n",
    "        return floats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of floatcustom():\n",
    "\n",
    "print(floatcustom('-153.534-108.134'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkflattened(l: list):\n",
    "    '''Specific function for handling output from customfloat() - ensures list is flattened if it contains\n",
    "        a sublist and removes last element from different column\n",
    "    '''\n",
    "    flattened_ = []\n",
    "    contains_sublist = False\n",
    "    for i in l:\n",
    "        if isinstance(i, list):\n",
    "            contains_sublist = True\n",
    "            for j in i:\n",
    "                flattened_.append(j)\n",
    "        else:\n",
    "            flattened_.append(i)\n",
    "    if contains_sublist:\n",
    "        del flattened_[-1]\n",
    "    return flattened_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of checkflattened():\n",
    "\n",
    "test_list = ['1', ['2', '3'], '4']\n",
    "checkflattened(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdbParser(pdbtext: str) -> dict:\n",
    "    '''Returns two dictionaries associated with basic info for the PDB and the PDB atom information\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pdbtext : str\n",
    "        The full text of a PDB provided as a string\n",
    "\n",
    "    '''\n",
    "    info_ = {\n",
    "            'HEADER' : None,\n",
    "            'TITLE' : None, # Will hold lists to be subsequently parsed\n",
    "            'SOURCE' : [],\n",
    "            'REMARKS' : [],\n",
    "            }\n",
    "    protein_ = {'ATOM' : [], 'HETATM' : []} # Will hold lists to be subsequently parsed\n",
    "    listofstrings = pdbtext.split('\\n')\n",
    "    listofstrings = [' '.join(substring.split()) for substring in listofstrings] # make only space separated\n",
    "    for substring in listofstrings:\n",
    "        split = substring.split(' ')\n",
    "        if split[0] in tuple(info_.keys()):\n",
    "            if split[0] == 'HEADER' or split[0] == 'TITLE':\n",
    "                info_[split[0]] = split[1:]\n",
    "            else:\n",
    "                info_[split[0]].append(split[1:])\n",
    "        elif split[0] in protein_.keys():\n",
    "            xyz = checkflattened([floatcustom(i) for i in split[6:9]])\n",
    "            if len(xyz) != 3:\n",
    "                return None\n",
    "            p_ = {\n",
    "                'serial' : split[1],\n",
    "                'name' : split[2],\n",
    "                'resname' : split[3],\n",
    "                'chain' : split[4],\n",
    "                'resid' : split[5],\n",
    "                'xyz' : checkflattened([floatcustom(i) for i in split[6:9]])\n",
    "                 }\n",
    "            protein_[split[0]].append(p_)\n",
    "    return info_, protein_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-video",
   "metadata": {},
   "source": [
    "Next, we will write a function to acquire data from the PDB without downloading the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(key: str, index=None, plot=False) -> list: # <-- Notice the Python3.x new syntax for type hints\n",
    "    '''Returns relevant data for proteins associated with the provided key\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        The category supplied for PDB searches\n",
    "        \n",
    "    index (optional): int or None (default: None)\n",
    "        The index of a single PDBs to extract data from\n",
    "        \n",
    "    plot (optional): bool (default: False)\n",
    "        Boolean to decide whether to plot the protein or not (Note: index must be an int)\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised if the provided key cannot be converted to a string.\n",
    "        Raised if 'index' keyword argument is not an integer.\n",
    "    '''\n",
    "    try:\n",
    "        key = str(key)\n",
    "    except:\n",
    "        raise ValueError('Key must be able to be cast as a string literal.')\n",
    "    if plot == True:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "    pdb_entries = Query(key).search()\n",
    "    if index != None and isinstance(index, int):\n",
    "        pdb = get_pdb_file(pdb_entries[index])\n",
    "        info, protein = pdbParser(pdb)\n",
    "        coords = [atom['xyz'] for atom in protein['ATOM']]\n",
    "        if plot == True:\n",
    "            c = np.asarray(coords)\n",
    "            ax.plot(c[:, 0], c[:, 1], c[:, 2], lw=0.5)\n",
    "        plt.show()\n",
    "    elif index == None:\n",
    "        for i in range(pdb_entries):\n",
    "            pdb = get_pdb_file(pdb_entries[i])\n",
    "            info, protein = pdbParser(pdb)\n",
    "    else:\n",
    "        raise ValueError('index keyword must be an integer.')\n",
    "\n",
    "getData('integral membrane', index=12, plot=True)\n",
    "getData('peripheral membrane', index=1, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-updating",
   "metadata": {},
   "source": [
    "We want to know which residues are most prevalent on the outer portions of the protein. Let's write a function which takes in coordinates (ignoring vdW radii) and renders a ranking of residues which are \"solvent exposed\".\n",
    "\n",
    "There are other (and much more accurate) ways of doing this (SASA), but for this demonstration we will simply use the distance from the geometric center of the protein as our metric. We will take the top 5% of the residues (threshold value) that are farthest from the center and consider them to be the most solvent exposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSolventExposed(protein, threshold=5):\n",
    "    '''Returns a dictionary containing residue names and the number of atoms on the outer portion of the protein\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    protein : dict\n",
    "        dictionary containing protein PDB information produced by pdbParser()\n",
    "        \n",
    "    threshold (optional): float (default: 5)\n",
    "        the top percent of residues which qualify as the most exposed\n",
    "        \n",
    "    '''\n",
    "    c = np.stack(np.asarray([np.asarray(atom['xyz']) for atom in protein['ATOM']]), axis=0)\n",
    "    resname_list = np.asarray([atom['resname'] for atom in protein['ATOM']])\n",
    "    center = (np.average(np.asarray(c)[:, 0]), np.average(np.asarray(c)[:, 1]), np.average(np.asarray(c)[:, 2]))\n",
    "    distance = lambda c_tuple : np.sqrt((c_tuple[0]-center[0])**2 + (c_tuple[1]-center[1])**2 + (c_tuple[2]-center[2])**2)\n",
    "    distances = np.asarray([distance(coord) for n, coord in enumerate(c)])\n",
    "    indices = np.argsort(distances)[::-1] # sort from highest to lowest distance - return the indices\n",
    "    resname_sorted = resname_list[indices]\n",
    "    distances_sorted = distances[indices]\n",
    "    percent = 0\n",
    "    top_residues = []\n",
    "    for r in resname_sorted:\n",
    "        percent += 1/len(resname_sorted) * 100\n",
    "        top_residues.append(r)\n",
    "        if percent >= threshold:\n",
    "            break\n",
    "    d_ = {i:top_residues.count(i) for i in top_residues} # Unique resnames : # of atoms\n",
    "    return d_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-wagner",
   "metadata": {},
   "source": [
    "Let's now add this function to our getData function.\n",
    "\n",
    "First, we will need to write a function to add dictionaries key-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDictKeys(dtarget, add):\n",
    "    '''Function to add to a dictionary by key-value pair\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dtarget : target dictionary to add to\n",
    "    add : the dictionary we are adding\n",
    "    '''\n",
    "    for addkey in tuple(add.keys()):\n",
    "        if addkey in dtarget.keys():\n",
    "            dtarget[addkey] += add[addkey]\n",
    "        else:\n",
    "            dtarget.update({'{}'.format(addkey) : add[addkey]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how addDictKeys() is used:\n",
    "\n",
    "d1 = {'one' : 1, 'two' : 2, 'three' : 3}\n",
    "d2 = {'one' : 10, 'two' : 10, 'three' : 10}\n",
    "\n",
    "addDictKeys(d1, d2)\n",
    "\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(key: str, index=None, plot=False) -> dict: # <-- Notice the Python3.x new syntax for type hints\n",
    "    '''Returns dictionary containing a sum of the top x% solvent exposed residues by atom count\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        The category supplied for PDB searches\n",
    "        \n",
    "    index (optional): int or None (default: None)\n",
    "        The index of a single PDBs to extract data from\n",
    "        \n",
    "    plot (optional): bool (default: False)\n",
    "        Boolean to decide whether to plot the protein or not (Note: index must be an int)\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised if the provided key cannot be converted to a string.\n",
    "        Raised if 'index' keyword argument is not an integer.\n",
    "    '''\n",
    "    dataDict = {}\n",
    "    try:\n",
    "        key = str(key)\n",
    "    except:\n",
    "        raise ValueError('Key must be able to be cast as a string literal.')\n",
    "    if plot == True:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "    pdb_entries = Query(key).search()\n",
    "    if index != None and isinstance(index, int):\n",
    "        pdb = get_pdb_file(pdb_entries[index])\n",
    "        info, protein = pdbParser(pdb)\n",
    "        coords = [atom['xyz'] for atom in protein['ATOM']]\n",
    "        if plot == True:\n",
    "            c = np.asarray(coords)\n",
    "            ax.plot(c[:, 0], c[:, 1], c[:, 2], lw=0.5)\n",
    "        plt.show()\n",
    "        exposedDict = getSolventExposed(protein)\n",
    "        addDictKeys(dataDict, exposedDict)\n",
    "    elif index == None:\n",
    "        for i in range(pdb_entries):\n",
    "            pdb = get_pdb_file(pdb_entries[i])\n",
    "            info, protein = pdbParser(pdb)\n",
    "    else:\n",
    "        raise ValueError('index keyword must be an integer.')\n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "data = getData('integral membrane', index=12)\n",
    "end = time.time()\n",
    "print('Time required for a single protein: {} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-airline",
   "metadata": {},
   "source": [
    "Let's do a quick profiling of the time this function takes before we run it on >200,000 proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtimes = []\n",
    "total = 50\n",
    "while len(dtimes) <= total:\n",
    "    print('{}% completed.'.format(round((len(dtimes)/total)* 100)), end='\\r')\n",
    "    start = time.time()\n",
    "    getData('integral membrane', index=12)\n",
    "    stop = time.time()\n",
    "    dtimes.append(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(dtimes, ax=ax)\n",
    "ax.axvline(x=np.average(dtimes), color='r')\n",
    "plt.show()\n",
    "print(f'Averge time (for the tested protein size): {np.average(dtimes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-summit",
   "metadata": {},
   "source": [
    "So if we will run this code for the >200,000 proteins we plan to run it on it would take at least:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} days.'.format(200_000 * np.average(dtimes) / 3600 / 24))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-diameter",
   "metadata": {},
   "source": [
    "We need to speed this up in order to gather the results in a timely fashion.\n",
    "\n",
    "There are a couple of ways to speed code up:\n",
    "\n",
    "1. Throw more cores at it (parallelization)\n",
    "2. Vectorize the code (use numpy as much as possible)\n",
    "3. Cythonize\n",
    "4. Stop using Python all together in favor of a mid-level programming language (C/C++)\n",
    "5. Profile and modify our algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-wiring",
   "metadata": {},
   "source": [
    "We should take the time to narrow down where our code is bottle-necking. In other words, we should take the time to see where our code is not fully optimized within Python.\n",
    "\n",
    "We can do this systematically (https://docs.python.org/3/library/profile.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats, io\n",
    "\n",
    "def profile(f):\n",
    "    '''Decorator using cProfile to profile a given function\n",
    "    '''\n",
    "    def inner(*args, **kwargs):\n",
    "        pr = cProfile.Profile()\n",
    "        pr.enable()\n",
    "        v = f(*args, **kwargs)\n",
    "        pr.disable()\n",
    "        stream = io.StringIO()\n",
    "        ps = pstats.Stats(pr, stream=stream).sort_stats('cumulative')\n",
    "        ps.print_stats()\n",
    "        print(stream.getvalue())\n",
    "        return v\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def getData(key: str, index=None, plot=False) -> dict:\n",
    "    '''Returns dictionary containing a sum of the top x% solvent exposed residues by atom count\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        The category supplied for PDB searches\n",
    "        \n",
    "    index (optional): int or None (default: None)\n",
    "        The index of a single PDBs to extract data from\n",
    "        \n",
    "    plot (optional): bool (default: False)\n",
    "        Boolean to decide whether to plot the protein or not (Note: index must be an int)\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised if the provided key cannot be converted to a string.\n",
    "        Raised if 'index' keyword argument is not an integer.\n",
    "    '''\n",
    "    dataDict = {}\n",
    "    try:\n",
    "        key = str(key)\n",
    "    except:\n",
    "        raise ValueError('Key must be able to be cast as a string literal.')\n",
    "    if plot == True:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "    pdb_entries = Query(key).search()\n",
    "    if index != None and isinstance(index, int):\n",
    "        pdb = get_pdb_file(pdb_entries[index])\n",
    "        info, protein = pdbParser(pdb)\n",
    "        coords = [atom['xyz'] for atom in protein['ATOM']]\n",
    "        if plot == True:\n",
    "            c = np.asarray(coords)\n",
    "            ax.plot(c[:, 0], c[:, 1], c[:, 2], lw=0.5)\n",
    "        plt.show()\n",
    "        exposedDict = getSolventExposed(protein)\n",
    "        addDictKeys(dataDict, exposedDict)\n",
    "    elif index == None:\n",
    "        for i in range(pdb_entries):\n",
    "            pdb = get_pdb_file(pdb_entries[i])\n",
    "            info, protein = pdbParser(pdb)\n",
    "            exposedDict = getSolventExposed(protein)\n",
    "            addDictKeys(dataDict, exposedDict)\n",
    "    else:\n",
    "        raise ValueError('index keyword must be an integer.')\n",
    "    return dataDict\n",
    "\n",
    "getData('integral membrane', index=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-wallet",
   "metadata": {},
   "source": [
    "From here we can see that most of the time of our function is taken in retrieving the information from the PDB. If we wanted this code to run faster, we could first download all the required PDB file text locally and then optimize.\n",
    "\n",
    "Additionally, we can parallelize this code using Python's *multiprocessing* library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-panel",
   "metadata": {},
   "source": [
    "Tasks to make this more feasible:\n",
    "\n",
    "1. Download a subset of PDBs for benchmarking purposes\n",
    "2. Optimize\n",
    "3. Parallelize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-differential",
   "metadata": {},
   "source": [
    "#### 1. Write a function to download a subset of PDBs to current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def downloadPDBs(key: str, reduced=True, amount=10):\n",
    "    os.mkdir(os.getcwd()+'/'+key)\n",
    "    pdb_entries = Query(key).search()\n",
    "    if reduced:\n",
    "        pdb_entries = pdb_entries[:amount] # Get first 10\n",
    "        for i in pdb_entries:\n",
    "            try:\n",
    "                pdbstring = get_pdb_file(i)\n",
    "                file_str = os.getcwd()+'/'+key+'/'+i+'.pdb'\n",
    "                with open(file_str, 'w') as fp:\n",
    "                    fp.write(pdbstring)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    else:\n",
    "        for i in pdb_entries:\n",
    "            try:\n",
    "                pdbstring = get_pdb_file(i)\n",
    "                file_str = os.getcwd()+'/'+key+'/'+i+'.pdb'\n",
    "                with open(file_str, 'w') as fp:\n",
    "                    fp.write(pdbstring)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadPDBs('integral membrane');\n",
    "downloadPDBs('peripheral membrane');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-routine",
   "metadata": {},
   "source": [
    "Let's check the speed of our \"getData\" function after modifying it for extracting from local .pdb files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # <-- import for getting all files from local directories\n",
    "\n",
    "def getData(key: str, index=None, plot=False) -> dict:\n",
    "    '''Returns dictionary containing a sum of the top x% solvent exposed residues by atom count\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        The category supplied for PDB searches\n",
    "        \n",
    "    index (optional): int or None (default: None)\n",
    "        The index of a single PDBs to extract data from\n",
    "        \n",
    "    plot (optional): bool (default: False)\n",
    "        Boolean to decide whether to plot the protein or not (Note: index must be an int)\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised if the provided key cannot be converted to a string.\n",
    "        Raised if 'index' keyword argument is not an integer.\n",
    "    '''\n",
    "    dataDict = {}\n",
    "    try:\n",
    "        key = str(key)\n",
    "    except:\n",
    "        raise ValueError('Key must be able to be cast as a string literal.')\n",
    "    if plot == True:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "    #pdb_entries = Query(key).search() <-- replacing this\n",
    "    pdb_entries = os.listdir(key) # <---\n",
    "    if index != None and isinstance(index, int):\n",
    "        file =  os.getcwd() + '/' + key + '/' + pdb_entries[index]\n",
    "        pdb = ''.join(open(file, 'r').read())\n",
    "        if pdbParser(pdb) == None:\n",
    "            raise TypeError('pdbParser returned None for the indexed PDB -- try another PDB index.')\n",
    "        info, protein = pdbParser(pdb)\n",
    "        coords = [atom['xyz'] for atom in protein['ATOM']]\n",
    "        if plot == True:\n",
    "            c = np.asarray(coords)\n",
    "            ax.plot(c[:, 0], c[:, 1], c[:, 2], lw=0.5)\n",
    "        plt.show()\n",
    "        exposedDict = getSolventExposed(protein)\n",
    "        addDictKeys(dataDict, exposedDict)\n",
    "    elif index == None:\n",
    "        for n, i in enumerate(pdb_entries):\n",
    "            file = os.getcwd() + '/' + key + '/' + i\n",
    "            #pdb = get_pdb_file(file) <-- replacing this since we no longer have to \"get\" the PDB\n",
    "            pdb = ''.join(open(file, 'r').read()) #<--\n",
    "            if pdbParser(pdb) == None:\n",
    "                continue # skip iteration if pdbParser() decides to skip the PDB by returning 'None'\n",
    "            info, protein = pdbParser(pdb)\n",
    "            exposedDict = getSolventExposed(protein)\n",
    "            addDictKeys(dataDict, exposedDict)\n",
    "    else:\n",
    "        raise ValueError('index keyword must be an integer.')\n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral = getData('integral membrane')\n",
    "print(integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripheral = getData('peripheral membrane')\n",
    "print(peripheral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-bridge",
   "metadata": {},
   "source": [
    "With this subset of data (10 proteins in each category) we can see a trend beginning to emerge with LYS residues seemingly having more exposure on the outer portions of the proteins that participate in intermitent membrane association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-debut",
   "metadata": {},
   "source": [
    "First let's get an estimate for the time of our function now that we have removed the use of the 'requests' module by downloading the PDBs first then running our functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "times = []\n",
    "for i in range(50):\n",
    "    start = time.time()\n",
    "    getData('peripheral membrane', index=3)\n",
    "    stop = time.time()\n",
    "    times.append(stop-start)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(1, np.average(times), width=1, ec='k', color='g')\n",
    "ax.bar(2, np.average(dtimes), width=1, ec='k', color='r')\n",
    "ax.set_xlim([-2, 5])\n",
    "plt.show()\n",
    "\n",
    "print('Original average time: {}'.format(np.average(dtimes)))\n",
    "print('New average time: {}'.format(np.average(times)))\n",
    "print('Estimated Speed-up: {} fold increase'.format(round((np.average(dtimes)-np.average(times))/np.average(dtimes)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estimated time for ~200,000 proteins: {} hours'.format(np.average(times)*200_000 / 3600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-touch",
   "metadata": {},
   "source": [
    "This is much better. Even without parallelization and code optimization this will take only a few hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-option",
   "metadata": {},
   "source": [
    "Looking back at our data, let's visualize the trends for the 10 protein subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_integral = dict(sorted(integral.items(), key=lambda x : x[0].lower()))\n",
    "sorted_peripheral = dict(sorted(peripheral.items(), key=lambda x : x[0].lower())) # Sort alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot([i for i in range(len(sorted_integral))], sorted_integral.values())\n",
    "ax.plot([i for i in range(len(sorted_peripheral))], sorted_peripheral.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-tuner",
   "metadata": {},
   "source": [
    "At first glance, it looks like categories (integral / peripheral) have opposing trends.\n",
    "\n",
    "Data Science Related Hypothesis: Peripheral proteins will demonstrate an opposing trend to integral proteins when evaluating which residues are likely solvent exposed \n",
    "\n",
    "Chemistry Related Hypothesis: Peripheral proteins will show a higher incidence of solvent exposed, positively charged, residues to facilitate reversible association to anionic lipid species at the membrane surface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-bristol",
   "metadata": {},
   "source": [
    "#### Let's make this a bit faster by parallelizing our code with one function being ran per CPU simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mpl\n",
    "\n",
    "print('I have {} CPUs on my computer.'.format(mpl.cpu_count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-ladder",
   "metadata": {},
   "source": [
    "Using the mpl library for running 'getData()' on each CPU from our Jupyter Notebook requires us to import it.\n",
    "\n",
    "We created a file in our current working directory which contains getData() and its associated functions for importation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "import defs\n",
    "\n",
    "pool = mpl.Pool(processes=mpl.cpu_count()) # <-- # of processes = 4\n",
    "results = pool.map(defs.getData, ('integral membrane', 'peripheral membrane'))\n",
    "pool.close()\n",
    "pool.join()\n",
    "print('Completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-design",
   "metadata": {},
   "source": [
    "Let's check the speed now with the code now parallelized to run on 4 CPUs simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import defs\n",
    "from functools import partial\n",
    "\n",
    "mpl_times = []\n",
    "pool = mpl.Pool(processes=mpl.cpu_count())\n",
    "\n",
    "for i in range(50):\n",
    "    start = time.time()\n",
    "    par = partial(defs.getData, index=3)\n",
    "    pool.map(par, ('peripheral membrane',))\n",
    "    stop = time.time()\n",
    "    mpl_times.append(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(1, np.average(mpl_times), width=1, ec='k', color='b')\n",
    "plt.plot(1, np.average(mpl_times)+.5, marker=r'$\\downarrow$', ms=20, color='k')\n",
    "ax.bar(2, np.average(times), width=1, ec='k', color='g')\n",
    "ax.bar(3, np.average(dtimes), width=1, ec='k', color='r')\n",
    "ax.set_xlim([-2, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-treaty",
   "metadata": {},
   "source": [
    "Very similar times to what we were getting with serial computations.\n",
    "\n",
    "We should keep in mind the following:\n",
    "\n",
    "* The benchmarking here isn't absolute. I may have other programs running locally that could be interfering with this test.\n",
    "\n",
    "* The time taken for computation will fluctate depending on protein size (here we only test 1 protein at index = 3)\n",
    "\n",
    "* Greater CPU count doesn't necessarily mean faster speeds. We should plot computation time as a function of processors to examine the optimal number of CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-swift",
   "metadata": {},
   "source": [
    "Now we will perform our \"full analysis\" with a subset of the data (1000) proteins.\n",
    "\n",
    "Let's download the first 200 proteins for our categories and then push them out to Amarel for speed tests and final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -r integral\\ membrane/\n",
    "rm -r peripheral\\ membrane/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadPDBs('integral membrane', reduced=True, amount=1000)\n",
    "downloadPDBs('peripheral membrane', reduced=True, amount=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "du -h integral\\ membrane\n",
    "du -h peripheral\\ membrane\n",
    "\n",
    "# Count the number of PDBs in each\n",
    "echo \"\"\n",
    "count=0; for i in integral\\ membrane/*; do count=$(($count+1)); done; echo \"$count files in integral\"\n",
    "count=0; for i in peripheral\\ membrane/*; do count=$(($count+1)); done; echo \"$count files in peripheral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-avatar",
   "metadata": {},
   "source": [
    "We did the same speed test from above except on increase numbers of CPUs on Amarel (data under amarel_speeds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted # For convenience\n",
    "speed_data = []\n",
    "for (root, path, files) in os.walk('amarel_speeds'):\n",
    "    for dat in files:\n",
    "        speed_data.append(root+'/'+dat)\n",
    "print(natsorted(speed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_data_numeric = [] # Read the data in as floats\n",
    "for data in speed_data:\n",
    "    with open(data, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for n, i in enumerate(lines):\n",
    "            lines[n] = float(lines[n])\n",
    "    speed_data_numeric.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for k, speed in enumerate(speed_data_numeric):\n",
    "    ax.bar(k, np.average(speed), width=1, ec='k', fc='w')\n",
    "    ax.errorbar(k, np.average(speed), yerr=np.std(speed), color='k')\n",
    "    ax.set_xticklabels(['', '4', '8', '16', '32', '64', '128']);\n",
    "    \n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xlabel('Number of CPUs')\n",
    "plt.ylim(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-robert",
   "metadata": {},
   "source": [
    "Looks like 32-64 CPUs is our sweet spot, however the change isn't very dramatic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-quilt",
   "metadata": {},
   "source": [
    "Let's examine the data for the final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_data = getData('integral membrane');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(integral_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripheral_data = getData('peripheral membrane');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_integral_data = dict(sorted(integral_data.items(), key=lambda x : x[0].lower()))\n",
    "sorted_peripheral_data = dict(sorted(peripheral_data.items(), key=lambda x : x[0].lower())) # Sort alphabetically\n",
    "\n",
    "print(sorted_integral_data)\n",
    "print(sorted_peripheral_data)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([i for i in range(len(sorted_integral_data))], sorted_integral_data.values())\n",
    "ax.plot([i for i in range(len(sorted_peripheral_data))], sorted_peripheral_data.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-boston",
   "metadata": {},
   "source": [
    "We've also pulled up some atypical residues. Let's filter these out for a comparison between canonical residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "cresidues = ('ALA', 'ASP', 'ASN', 'ARG', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', 'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = {}\n",
    "for key in sorted_integral_data:\n",
    "     if key in cresidues:\n",
    "          sid.update({key : sorted_integral_data[key]})\n",
    "pid = {}\n",
    "for key in sorted_peripheral_data:\n",
    "     if key in cresidues:\n",
    "          pid.update({key : sorted_peripheral_data[key]})\n",
    "        \n",
    "print(sid)\n",
    "print(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-newsletter",
   "metadata": {},
   "source": [
    "Not too much of a difference. Let's check that the proteins of peripheral and integral are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfiles = None\n",
    "ifiles = None\n",
    "for (root, paths, files) in os.walk('./peripheral membrane'):\n",
    "    pfiles = files\n",
    "for (root, paths, files) in os.walk('./integral membrane'):\n",
    "    ifiles = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSimilarity(list1, list2):\n",
    "    total_ = 0\n",
    "    same_count_ = 0\n",
    "    if len(list1) < len(list2):\n",
    "        total_ = len(list1)\n",
    "        for n, i in enumerate(list1):\n",
    "            if list1[n] == list2[n]:\n",
    "                same_count_ += 1\n",
    "    elif len(list2) < len(list1):\n",
    "        total_ = len(list2)\n",
    "        for n, i in enumerate(list2):\n",
    "            if list2[n] == list1[n]:\n",
    "                same_count_ += 1\n",
    "    return (same_count_ / total_) * 100                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_similar = checkSimilarity(pfiles, ifiles)\n",
    "print('There are only ~{}% shared PDBs between the two data sets.'.format(round(percent_similar, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-model",
   "metadata": {},
   "source": [
    "We could certainly do more to ensure that the 'peripheral' and 'integral' proteins are truly representative of their respective categories, but for this is fine for our session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by value for Histogram Plotting\n",
    "sid = dict(sorted(sid.items(), key=lambda item: item[1], reverse=True))\n",
    "pid = dict(sorted(pid.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.bar([i*2+.25 for i in range(len(sid))], sid.values()) # integral\n",
    "ax.bar([(i*2)-.5 for i in range(len(pid))], pid.values()) # peripheral\n",
    "ax.set_xticks([(i*2) for i in range(len(pid.keys()))])\n",
    "ax.set_xticklabels(list(pid.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-laugh",
   "metadata": {},
   "source": [
    "Overall, charged (hydrophilic) residues are exposed to a greater degress than netural / hydrophobic residues.\n",
    "\n",
    "Charged residues are more exposed in peripheral membrane proteins. However, we will need to perform the analysis on >1000 proteins and examine the statistical significance of this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-helicopter",
   "metadata": {},
   "source": [
    "We can now generalize our 'getData()' function to accomodate other functions for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(key: str, function, index=None, plot=False) -> dict:\n",
    "    '''Returns dictionary containing sum of function output\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    key : str\n",
    "        The category supplied for PDB searches\n",
    "        \n",
    "    function : function\n",
    "        function used for analysis - accepts 'protein' dict and returns a dict\n",
    "        \n",
    "    index (optional): int or None (default: None)\n",
    "        The index of a single PDBs to extract data from\n",
    "        \n",
    "    plot (optional): bool (default: False)\n",
    "        Boolean to decide whether to plot the protein or not (Note: index must be an int)\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Raised if the provided key cannot be converted to a string.\n",
    "        Raised if 'index' keyword argument is not an integer.\n",
    "    '''\n",
    "    dataDict = {}\n",
    "    try:\n",
    "        key = str(key)\n",
    "    except:\n",
    "        raise ValueError('Key must be able to be cast as a string literal.')\n",
    "    if plot == True:\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "    pdb_entries = os.listdir(key)\n",
    "    if index != None and isinstance(index, int):\n",
    "        file =  os.getcwd() + '/' + key + '/' + pdb_entries[index]\n",
    "        pdb = ''.join(open(file, 'r').read())\n",
    "        if pdbParser(pdb) == None:\n",
    "            raise TypeError('pdbParser returned None for the indexed PDB -- try another PDB index.')\n",
    "        info, protein = pdbParser(pdb)\n",
    "        coords = [atom['xyz'] for atom in protein['ATOM']]\n",
    "        if plot == True:\n",
    "            c = np.asarray(coords)\n",
    "            ax.plot(c[:, 0], c[:, 1], c[:, 2], lw=0.5)\n",
    "        plt.show()\n",
    "        #exposedDict = getSolventExposed(protein) <-- replacing\n",
    "        fDict = function(protein) # <--\n",
    "        addDictKeys(dataDict, fDict)\n",
    "    elif index == None:\n",
    "        for n, i in enumerate(pdb_entries):\n",
    "            file = os.getcwd() + '/' + key + '/' + i\n",
    "            pdb = ''.join(open(file, 'r').read())\n",
    "            if pdbParser(pdb) == None:\n",
    "                continue\n",
    "            info, protein = pdbParser(pdb)\n",
    "            #exposedDict = getSolventExposed(protein) <-- replacing\n",
    "            fDict = function(protein)\n",
    "            addDictKeys(dataDict, fDict)\n",
    "    else:\n",
    "        raise ValueError('index keyword must be an integer.')\n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-scott",
   "metadata": {},
   "source": [
    "What we have done is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def A(function, arg):\n",
    "    return function(arg)\n",
    "\n",
    "A(f, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-sydney",
   "metadata": {},
   "source": [
    "Let's write another analysis function to test how this works in our 'getData()' function.\n",
    "\n",
    "We will estimate the net charge of a given protein at neutral pH. The expectation is that peripheral membrane proteins will be more charged overall than their integral membrane protein counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def netCharge(protein):\n",
    "    '''Returns a dictionary containing residue names and their total charge contribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    protein : dict\n",
    "        dictionary containing protein PDB information produced by pdbParser()\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    charges_ = {'CYS' : 0, 'TYR' : 0, 'HIS' : 0.25, 'ARG' : 1, 'LYS' : 1, 'ASP' : -1, 'GLU' : -1}\n",
    "    charged_ = {'CYS' : 0, 'TYR' : 0, 'HIS' : 0, 'ARG' : 0, 'LYS' : 0, 'ASP' : 0, 'GLU' : 0}\n",
    "    for n, atom in enumerate(protein['ATOM']):\n",
    "        if n > 0:\n",
    "            if protein['ATOM'][n]['resname'] != protein['ATOM'][n-1]['resname']:\n",
    "                if atom['resname'] in tuple(charges_.keys()):\n",
    "                    charged_[atom['resname']] += charges_[atom['resname']]\n",
    "    return charged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "getData('peripheral membrane', netCharge, index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-microphone",
   "metadata": {},
   "source": [
    "Now we can estimate the netcharge by adding up the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "peripheral_charge = sum(getData('peripheral membrane', netCharge, index=3).values())\n",
    "print(peripheral_charge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-survival",
   "metadata": {},
   "source": [
    "To recap on what we did in this session:\n",
    "\n",
    "1. Designed functions for PDB handling and data collection\n",
    "2. Basic analysis of code speeds and optimization potential\n",
    "3. Performed the analysis to reach \"conclusions\"\n",
    "\n",
    "Some things to do on your free time for practice:\n",
    "\n",
    "1. Write your own function (i.e. something other than 'solventExposed()' for analysis)\n",
    "2. Optimize the code using different algorithms than the ones used in these examples (cProfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
